{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.exceptions import ConnectionError\n",
    "from fake_useragent import UserAgent\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from apscheduler.schedulers.background import BackgroundScheduler\n",
    "from datetime import datetime\n",
    "from github import Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to request HTML text\n",
    "# require requests & fake_useragent package\n",
    "def getHTML(url): \n",
    "    try:\n",
    "        ua = UserAgent().random\n",
    "        header = {'user-agent':ua}\n",
    "        r = requests.get(url, headers = header, timeout=30)\n",
    "        r.raise_for_status() # raise error if r.status_code != 200\n",
    "        r.encoding = r.apparent_encoding\n",
    "        return r.text\n",
    "    except ConnectionError:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the NAMEs of the latest N files in Github repo\n",
    "def updateFILENAMEs(url,matchstr,n):\n",
    "    try:\n",
    "#         global fileNAMEs\n",
    "        html = getHTML(url)\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        # initialise a list to store the filenames\n",
    "        filenames = []\n",
    "        for a in soup.find_all('a'):\n",
    "            text = a.get_text()\n",
    "            if re.match(matchstr,text) is not None:\n",
    "                filenames.append(text)\n",
    "        filenames = filenames[-n:]\n",
    "        # upload to Github\n",
    "        # First create a Github instance:\n",
    "        g = Github(\"dde59fd520aa7102e518a9b0993e9bca2f8122a2\")\n",
    "        # Creat a repository object:\n",
    "        repo = g.get_repo(\"CASA-DV-Group3/AirQuality-0\")\n",
    "        # get the contents of the original file:\n",
    "        contents = repo.get_contents('assets/data/fileNAMEs.txt',ref='lyu')\n",
    "        # update the file contents:\n",
    "        repo.update_file(contents.path,'update latest geojson filenames on '+str(datetime.now()),str(filenames),contents.sha,branch=\"lyu\")\n",
    "        print(str(datetime.now())+'    '+'success')\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-19 22:17:33.687089    success\n"
     ]
    }
   ],
   "source": [
    "# initialise the parameters\n",
    "url = 'https://github.com/CASA-DV-Group3/AirQuality-0/tree/lyu/assets/data'\n",
    "matchstr = 'STATIONdata'\n",
    "n = 12\n",
    "updateFILENAMEs(url,matchstr,n)\n",
    "# # set up the scheduler\n",
    "# scheduler = BackgroundScheduler()\n",
    "# scheduler.add_job(updateFILENAMEs,'interval', args=[url,matchstr,n], hours=1, start_date='2019-05-20 00:00:00', end_date='2019-05-21 00:00:00')\n",
    "# scheduler.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
